{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yshalsager/OpenAI_Whisper_ytdlp/blob/master/OpenAI_Whisper_ar_ytdlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw5ButypVydc"
      },
      "source": [
        "# ÿ™ŸÅÿ±Ÿäÿ∫ ÿßŸÑÿµŸàÿ™Ÿäÿßÿ™ ÿ®ÿßÿ≥ÿ™ÿÆÿØŸÖ OpenAI Whisper\n",
        "\n",
        "Ÿáÿ∞ÿß ÿßŸÑŸÖŸÑŸÅ ŸÖÿ®ŸÜŸä ÿπŸÑŸâ [Ÿáÿ∞ÿß ÿßŸÑŸÖŸÑŸÅ](https://colab.research.google.com/gist/Kazuki-tam/04e85708e4fd1c4b8af180d317977f4d/whisper-mock-en.ipynb)\n",
        "\n",
        "\n",
        "## üìñ ŸÉŸäŸÅŸäÿ© ÿßŸÑÿßÿ≥ÿ™ÿÆÿØÿßŸÖ\n",
        "1. Run \"Setting up\".\n",
        "2. Open the folder icon from the left sidebar.\n",
        "3. Upload audio files into the `content`.\n",
        "4. Input the audio file name into `fileName`.\n",
        "5. Select output language.\n",
        "5. Run \"Transcription\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWIl4Ys54Ce6",
        "outputId": "5775304d-ef49-4258-88cf-950603cd12a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-u23cpmug\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-u23cpmug\n",
            "  Resolved https://github.com/openai/whisper.git to commit 5c1a8c10e762bf9c29fcf6b3e40f17bc8ab09864\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (9.0.0)\n",
            "Collecting transformers>=4.19.0\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230124) (0.16.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2.25.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->openai-whisper==20230124) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers>=4.19.0->openai-whisper==20230124) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2.10)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230124-py3-none-any.whl size=1179333 sha256=50bf43e6434227db51df5ca74317c171ccb3b135d6426894f6c5e3df6de60943\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xv4k43db/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tokenizers, ffmpeg-python, huggingface-hub, transformers, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.12.0 openai-whisper-20230124 tokenizers-0.13.2 transformers-4.26.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2023.1.6-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets\n",
            "  Downloading websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m107.0/107.0 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mutagen\n",
            "  Downloading mutagen-1.46.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m193.6/193.6 KB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from yt-dlp) (2022.12.7)\n",
            "Collecting brotli\n",
            "  Downloading Brotli-1.0.9-cp38-cp38-manylinux1_x86_64.whl (357 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m357.2/357.2 KB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex\n",
            "  Downloading pycryptodomex-3.17-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: brotli, websockets, pycryptodomex, mutagen, yt-dlp\n",
            "Successfully installed brotli-1.0.9 mutagen-1.46.0 pycryptodomex-3.17 websockets-10.4 yt-dlp-2023.1.6\n",
            "--2023-01-31 12:41:38--  https://raw.githubusercontent.com/jianfch/stable-ts/dcf3c55e6655ddee5694ad442c93d8f49fe476de/stable_whisper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68151 (67K) [text/plain]\n",
            "Saving to: ‚Äòstable_whisper.py‚Äô\n",
            "\n",
            "stable_whisper.py   100%[===================>]  66.55K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2023-01-31 12:41:38 (36.7 MB/s) - ‚Äòstable_whisper.py‚Äô saved [68151/68151]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title ÿßÔªπÿπÿØÿßÿØ\n",
        "# Install packages\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install yt-dlp\n",
        "!wget https://raw.githubusercontent.com/jianfch/stable-ts/dcf3c55e6655ddee5694ad442c93d8f49fe476de/stable_whisper.py -O stable_whisper.py\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Add folders\n",
        "download_folder = Path(\"download\")\n",
        "if not download_folder.exists():\n",
        "  download_folder.mkdir()\n",
        "output_folder = Path(\"output\")\n",
        "if not output_folder.exists():\n",
        "  output_folder.mkdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "scAiM8ug_s1M",
        "outputId": "76ca0704-d722-4372-9268-91485b9239ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: iQyL7hP2Drk\n",
            "[youtube] iQyL7hP2Drk: Downloading webpage\n",
            "[youtube] iQyL7hP2Drk: Downloading android player API JSON\n",
            "[info] iQyL7hP2Drk: Downloading 1 format(s): 140\n",
            "[download] Destination: download/NA-ÿ£ŸÑŸÅ ÿ®ÿßÿ° ÿßŸÑÿπŸÑŸàŸÖ ÔΩú ÿØÿ±ÿ≥ ÿßŸÑŸÜÿ≥ÿßÿ° ÔΩú ŸÅŸÇŸá ÿßŸÑÿ•ÿÆŸÑÿßÿµ 07-iQyL7hP2Drk.m4a\n",
            "[download] 100% of  154.63MiB in 00:00:14 at 10.93MiB/s  \n",
            "[FixupM4a] Correcting container of \"download/NA-ÿ£ŸÑŸÅ ÿ®ÿßÿ° ÿßŸÑÿπŸÑŸàŸÖ ÔΩú ÿØÿ±ÿ≥ ÿßŸÑŸÜÿ≥ÿßÿ° ÔΩú ŸÅŸÇŸá ÿßŸÑÿ•ÿÆŸÑÿßÿµ 07-iQyL7hP2Drk.m4a\"\n",
            "[ExtractAudio] Not converting audio download/NA-ÿ£ŸÑŸÅ ÿ®ÿßÿ° ÿßŸÑÿπŸÑŸàŸÖ ÔΩú ÿØÿ±ÿ≥ ÿßŸÑŸÜÿ≥ÿßÿ° ÔΩú ŸÅŸÇŸá ÿßŸÑÿ•ÿÆŸÑÿßÿµ 07-iQyL7hP2Drk.m4a; file is already in target format m4a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.87G/2.87G [01:03<00:00, 48.5MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription of download/NA-ÿ£ŸÑŸÅ ÿ®ÿßÿ° ÿßŸÑÿπŸÑŸàŸÖ ÔΩú ÿØÿ±ÿ≥ ÿßŸÑŸÜÿ≥ÿßÿ° ÔΩú ŸÅŸÇŸá ÿßŸÑÿ•ÿÆŸÑÿßÿµ 07-iQyL7hP2Drk.m4a will start!\n",
            "Detected language: arabic\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3693f2bf-838f-4721-8b3b-e9d75084628f\", \"NA-\\u0623\\u0644\\u0641 \\u0628\\u0627\\u0621 \\u0627\\u0644\\u0639\\u0644\\u0648\\u0645 \\uff5c \\u062f\\u0631\\u0633 \\u0627\\u0644\\u0646\\u0633\\u0627\\u0621 \\uff5c \\u0641\\u0642\\u0647 \\u0627\\u0644\\u0625\\u062e\\u0644\\u0627\\u0635 07-iQyL7hP2Drk.txt\", 176942)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/output/NA-ÿ£ŸÑŸÅ ÿ®ÿßÿ° ÿßŸÑÿπŸÑŸàŸÖ ÔΩú ÿØÿ±ÿ≥ ÿßŸÑŸÜÿ≥ÿßÿ° ÔΩú ŸÅŸÇŸá ÿßŸÑÿ•ÿÆŸÑÿßÿµ 07-iQyL7hP2Drk.srt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8dbd704d-3d4d-4efb-9954-f95239c3f8ba\", \"NA-\\u0623\\u0644\\u0641 \\u0628\\u0627\\u0621 \\u0627\\u0644\\u0639\\u0644\\u0648\\u0645 \\uff5c \\u062f\\u0631\\u0633 \\u0627\\u0644\\u0646\\u0633\\u0627\\u0621 \\uff5c \\u0641\\u0642\\u0647 \\u0627\\u0644\\u0625\\u062e\\u0644\\u0627\\u0635 07-iQyL7hP2Drk.srt\", 309790)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "#@title Transcription\n",
        "import whisper\n",
        "import yt_dlp\n",
        "\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "from stable_whisper import modify_model, results_to_sentence_srt\n",
        "\n",
        "youtube_urls = \"\"#@param {type:\"string\"}\n",
        "playlist_start = 1 #@param {type:\"integer\"}\n",
        "playlist_end = 9999 #@param {type:\"integer\"}\n",
        "\n",
        "ydl_opts = {\n",
        "    'format': 'm4a/bestaudio/best',\n",
        "    'postprocessors': [{  # Extract audio using ffmpeg\n",
        "        'key': 'FFmpegExtractAudio',\n",
        "        'preferredcodec': 'm4a',\n",
        "    }],\n",
        "    \"playliststart\": int(playlist_start),\n",
        "    \"playlistend\": int(playlist_end),\n",
        "    \"outtmpl\": f\"{str(download_folder)}/%(playlist_index)04d-%(title)s-%(id)s.%(ext)s\"\n",
        "}\n",
        "\n",
        "for youtube_url in youtube_urls.split():\n",
        "  with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "      ydl.download(youtube_url)\n",
        "\n",
        "language = \"ar\"#@param [\"en\", \"ar\", \"Afrikaans\", \"Albanian\", \"Amharic\", \"Arabic\", \"Armenian\", \"Assamese\", \"Azerbaijani\", \"Bashkir\", \"Basque\", \"Belarusian\", \"Bengali\", \"Bosnian\", \"Breton\", \"Bulgarian\", \"Burmese\", \"Castilian\", \"Catalan\", \"Chinese\", \"Croatian\", \"Czech\", \"Danish\", \"Dutch\", \"English\", \"Estonian\", \"Faroese\", \"Finnish\", \"Flemish\", \"French\", \"Galician\", \"Georgian\", \"German\", \"Greek\", \"Gujarati\", \"Haitian\", \"Haitian Creole\", \"Hausa\", \"Hawaiian\", \"Hebrew\", \"Hindi\", \"Hungarian\", \"Icelandic\", \"Indonesian\", \"Italian\", \"Japanese\", \"Javanese\", \"Kannada\", \"Kazakh\", \"Khmer\", \"Korean\", \"Lao\", \"Latin\", \"Latvian\", \"Letzeburgesch\", \"Lingala\", \"Lithuanian\", \"Luxembourgish\", \"Macedonian\", \"Malagasy\", \"Malay\", \"Malayalam\", \"Maltese\", \"Maori\", \"Marathi\", \"Moldavian\", \"Moldovan\", \"Mongolian\", \"Myanmar\", \"Nepali\", \"Norwegian\", \"Nynorsk\", \"Occitan\", \"Panjabi\", \"Pashto\", \"Persian\", \"Polish\", \"Portuguese\", \"Punjabi\", \"Pushto\", \"Romanian\", \"Russian\", \"Sanskrit\", \"Serbian\", \"Shona\", \"Sindhi\", \"Sinhala\", \"Sinhalese\", \"Slovak\", \"Slovenian\", \"Somali\", \"Spanish\", \"Sundanese\", \"Swahili\", \"Swedish\", \"Tagalog\", \"Tajik\", \"Tamil\", \"Tatar\", \"Telugu\", \"Thai\", \"Tibetan\", \"Turkish\", \"Turkmen\", \"Ukrainian\", \"Urdu\", \"Uzbek\", \"Valencian\", \"Vietnamese\", \"Welsh\", \"Yiddish\", \"Yoruba\", \"af\", \"am\", \"as\", \"az\", \"ba\", \"be\", \"bg\", \"bn\", \"bo\", \"br\", \"bs\", \"ca\", \"cs\", \"cy\", \"da\", \"de\", \"el\", \"es\", \"et\", \"eu\", \"fa\", \"fi\", \"fo\", \"fr\", \"gl\", \"gu\", \"ha\", \"haw\", \"hi\", \"hr\", \"ht\", \"hu\", \"hy\", \"id\", \"is\", \"it\", \"iw\", \"ja\", \"jw\", \"ka\", \"kk\", \"km\", \"kn\", \"ko\", \"la\", \"lb\", \"ln\", \"lo\", \"lt\", \"lv\", \"mg\", \"mi\", \"mk\", \"ml\", \"mn\", \"mr\", \"ms\", \"mt\", \"my\", \"ne\", \"nl\", \"nn\", \"no\", \"oc\", \"pa\", \"pl\", \"ps\", \"pt\", \"ro\", \"ru\", \"sa\", \"sd\", \"si\", \"sk\", \"sl\", \"sn\", \"so\", \"sq\", \"sr\", \"su\", \"sv\", \"sw\", \"ta\", \"te\", \"tg\", \"th\", \"tk\", \"tl\", \"tr\", \"tt\", \"uk\", \"ur\", \"uz\", \"vi\", \"yi\", \"yo\", \"zh\"]\n",
        "model = \"large\"#@param [\"large\", \"medium\", \"base\", \"small\", \"tiny\"]\n",
        "model = whisper.load_model(model)\n",
        "# jianfch/stable-ts\n",
        "modify_model(model)\n",
        "\n",
        "for audio_file in sorted(download_folder.glob(\"*.m4a\")):\n",
        "  print(f\"Transcription of {audio_file} will start!\")\n",
        "  text_file = Path(f\"{output_folder}/{audio_file.stem}.txt\")\n",
        "  subtitle_file = Path(f\"{output_folder}/{audio_file.stem}.srt\")\n",
        "\n",
        "  result = model.transcribe(str(audio_file))\n",
        "  # save TXT\n",
        "  with open(str(text_file), \"w\", encoding=\"utf-8\") as txt:\n",
        "    for segment in result[\"segments\"]:\n",
        "        txt.write(segment['text'].strip() + '\\n')\n",
        "  files.download(str(text_file))\n",
        "  # save SRT\n",
        "  #with open(f\"{download_folder}/{audio_file.name}.srt\", \"w\", encoding=\"utf-8\") as srt:\n",
        "  #    whisper.write_srt(result[\"segments\"], file=srt)\n",
        "  results_to_sentence_srt(result, str(subtitle_file))\n",
        "  files.download(str(subtitle_file))\n",
        "  ## Write into a text file\n",
        "  #Path(f\"{download_folder}/{file_name.name}.txt\").write_text(result[\"text\"])\n",
        "  audio_file.unlink()\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nAs7OP7QrRa"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDTQuiH0JwC-"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IImQ8gCq_wYB"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}