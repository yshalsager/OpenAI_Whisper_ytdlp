{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yshalsager/OpenAI_Whisper_ytdlp/blob/master/OpenAI_Whisper_ar_ytdlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw5ButypVydc"
      },
      "source": [
        "<div dir=\"rtl\">\n",
        "<h1>ØªÙØ±ÙŠØº Ø§Ù„ØµÙˆØªÙŠØ§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ù… OpenAI Whisper</h1>\n",
        "\n",
        "Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ [Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù](https://colab.research.google.com/gist/Kazuki-tam/04e85708e4fd1c4b8af180d317977f4d/whisper-mock-en.ipynb)\n",
        "\n",
        "\n",
        "## ğŸ“– ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…\n",
        "1. Ø´ØºÙ„ Ø®Ø·ÙˆØ© \"Ø§ï»¹Ø¹Ø¯Ø§Ø¯\".\n",
        "2. Ø§Ø®ØªØ± Ù†Ù…Ø· Ø§Ù„ØªØ´ØºÙŠÙ„: ÙŠÙˆØªÙŠÙˆØ¨ Ø£Ùˆ Ù…Ù„Ù Ù…Ø­Ù„ÙŠ.\n",
        "  - Ø¥Ø°Ø§ Ø§Ø®ØªØ±Øª upload Ù„ØªÙØ±ÙŠØº Ù…Ù„Ù ØªÙ‚ÙˆÙ… Ø¨Ø±ÙØ¹Ù‡ Ø¨Ù†ÙØ³ÙƒØŒ  Ø´ØºÙ„ Ø®Ø·ÙˆØ© Ø§ï»¹Ø¹Ø¯Ø§Ø¯ Ø£ÙˆÙ„Ø§ Ø«Ù… Ø§Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ Ù…Ø¬Ù„Ø¯ `download`.\n",
        "  - Ø¥Ø°Ø§ Ø§Ø®ØªØ±Øª ÙŠÙˆØªÙŠÙˆØ¨ Ø¶Ø¹ Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ù‚Ø·Ø¹ Ø£Ùˆ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ ÙÙŠ `user_input`\n",
        "  - ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ø¯ÙŠØ¯ Ø¨Ø¯Ø§ÙŠØ© ÙˆÙ†Ù‡Ø§ÙŠØ© Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ Ù…Ù† Ø§Ù„Ø®ÙŠØ§Ø±ÙŠÙ† Ø§Ù„ØªØ§Ù„ÙŠÙŠÙ†.\n",
        "3. Ø§Ø®ØªØ± Ù„ØºØ© Ø§Ù„Ù…Ù„Ù.\n",
        "4. Ø§Ø®ØªØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙŠ Ø§Ù„ØªÙØ±ÙŠØºØŒ `large` ÙŠØ¹Ø·ÙŠ Ù†ØªØ§Ø¦Ø¬ Ø£ÙØ¶Ù„ Ù„ÙƒÙ† Ø£Ø¨Ø·Ø£.\n",
        "5. Ø´ØºÙ„ Ø®Ø·ÙˆØ© \"Ø§Ù„ØªÙØ±ÙŠØº\".\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWIl4Ys54Ce6"
      },
      "outputs": [],
      "source": [
        "#@title Ø§ï»¹Ø¹Ø¯Ø§Ø¯\n",
        "!apt install libcublas11\n",
        "!rm -f .mise.toml\n",
        "!MISE_VERSION=2025.1.14 curl https://mise.run | sh\n",
        "!~/.local/bin/mise --version\n",
        "!~/.local/bin/mise use --global python@3.11 -y\n",
        "!~/.local/bin/mise x -- python3 -m pip install --quiet --upgrade pip wheel setuptools\n",
        "!~/.local/bin/mise which python3\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# Create folders\n",
        "download_folder = Path(\"download\")\n",
        "if not download_folder.exists():\n",
        "    download_folder.mkdir()\n",
        "output_folder = Path(\"output\")\n",
        "if not output_folder.exists():\n",
        "    output_folder.mkdir()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpRknIHk6BxA",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/root/.local/share/mise/installs/python/3.11/lib/python3.11/site-packages')\n",
        "\n",
        "# @title Ø§Ù„ØªÙØ±ÙŠØº\n",
        "import mimetypes\n",
        "from pathlib import Path\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# These two functions are adapted from original whisper implementation\n",
        "def format_timestamp(seconds, always_include_hours=False, decimal_marker=\".\"):\n",
        "    if seconds is not None:\n",
        "      assert seconds >= 0, \"non-negative timestamp expected\"\n",
        "      milliseconds = round(seconds * 1000.0)\n",
        "      hours = milliseconds // 3_600_000\n",
        "      milliseconds -= hours * 3_600_000\n",
        "      minutes = milliseconds // 60_000\n",
        "      milliseconds -= minutes * 60_000\n",
        "      seconds = milliseconds // 1_000\n",
        "      milliseconds -= seconds * 1_000\n",
        "      hours_marker = f\"{hours:02d}:\" if always_include_hours or hours > 0 else \"\"\n",
        "      return (\n",
        "          f\"{hours_marker}{minutes:02d}:{seconds:02d}{decimal_marker}{milliseconds:03d}\"\n",
        "      )\n",
        "    else:\n",
        "        # we have a malformed timestamp so just return it as is\n",
        "        return seconds\n",
        "\n",
        "def write_srt(file, segments):\n",
        "    for i, segment in enumerate(segments, start=1):\n",
        "        if isinstance(segment, dict):\n",
        "            segment_start = segment[\"start\"]\n",
        "            segment_end = segment[\"end\"]\n",
        "            segment_text = segment[\"text\"]\n",
        "        else:\n",
        "            segment_start = segment.start\n",
        "            segment_end = segment.end\n",
        "            segment_text = segment.text\n",
        "        start_time = format_timestamp(\n",
        "            segment_start, always_include_hours=True, decimal_marker=\",\"\n",
        "        )\n",
        "        end_time = format_timestamp(\n",
        "            segment_end, always_include_hours=True, decimal_marker=\",\"\n",
        "        )\n",
        "        file.write(\"%d\\n\" % i)\n",
        "        file.write(\"%s --> %s\\n\" % (start_time, end_time))\n",
        "        file.write(segment_text.strip().replace(\"-->\", \"->\"))\n",
        "        file.write(\"\\n\\n\")\n",
        "\n",
        "new_line_separators = {\n",
        "    \"White space ( )\": \" \",\n",
        "    \"Line feed (\\\\n)\": \"\\n\",\n",
        "    \"Carriage return + Line feed (\\\\r\\\\n)\": \"\\r\\n\",\n",
        "    \"Carriage return (\\\\r)\": \"\\r\"\n",
        "}\n",
        "\n",
        "# options\n",
        "converter = \"faster-whisper\"  # @param [\"whisper\", \"faster-whisper\", \"whisper-jax\", \"insanely-fast-whisper\"]\n",
        "process_type = \"youtube\"  # @param [\"youtube\", \"google_drive\", \"upload\", \"direct_link\", \"curl\"]\n",
        "user_input = \"\"  # @param {type:\"string\"}\n",
        "playlist_start = 1  # @param {type:\"integer\"}\n",
        "playlist_end = 9999  # @param {type:\"integer\"}\n",
        "language = \"ar\"  # @param [\"en\", \"ar\", \"Afrikaans\", \"Albanian\", \"Amharic\", \"Arabic\", \"Armenian\", \"Assamese\", \"Azerbaijani\", \"Bashkir\", \"Basque\", \"Belarusian\", \"Bengali\", \"Bosnian\", \"Breton\", \"Bulgarian\", \"Burmese\", \"Castilian\", \"Catalan\", \"Chinese\", \"Croatian\", \"Czech\", \"Danish\", \"Dutch\", \"English\", \"Estonian\", \"Faroese\", \"Finnish\", \"Flemish\", \"French\", \"Galician\", \"Georgian\", \"German\", \"Greek\", \"Gujarati\", \"Haitian\", \"Haitian Creole\", \"Hausa\", \"Hawaiian\", \"Hebrew\", \"Hindi\", \"Hungarian\", \"Icelandic\", \"Indonesian\", \"Italian\", \"Japanese\", \"Javanese\", \"Kannada\", \"Kazakh\", \"Khmer\", \"Korean\", \"Lao\", \"Latin\", \"Latvian\", \"Letzeburgesch\", \"Lingala\", \"Lithuanian\", \"Luxembourgish\", \"Macedonian\", \"Malagasy\", \"Malay\", \"Malayalam\", \"Maltese\", \"Maori\", \"Marathi\", \"Moldavian\", \"Moldovan\", \"Mongolian\", \"Myanmar\", \"Nepali\", \"Norwegian\", \"Nynorsk\", \"Occitan\", \"Panjabi\", \"Pashto\", \"Persian\", \"Polish\", \"Portuguese\", \"Punjabi\", \"Pushto\", \"Romanian\", \"Russian\", \"Sanskrit\", \"Serbian\", \"Shona\", \"Sindhi\", \"Sinhala\", \"Sinhalese\", \"Slovak\", \"Slovenian\", \"Somali\", \"Spanish\", \"Sundanese\", \"Swahili\", \"Swedish\", \"Tagalog\", \"Tajik\", \"Tamil\", \"Tatar\", \"Telugu\", \"Thai\", \"Tibetan\", \"Turkish\", \"Turkmen\", \"Ukrainian\", \"Urdu\", \"Uzbek\", \"Valencian\", \"Vietnamese\", \"Welsh\", \"Yiddish\", \"Yoruba\", \"af\", \"am\", \"as\", \"az\", \"ba\", \"be\", \"bg\", \"bn\", \"bo\", \"br\", \"bs\", \"ca\", \"cs\", \"cy\", \"da\", \"de\", \"el\", \"es\", \"et\", \"eu\", \"fa\", \"fi\", \"fo\", \"fr\", \"gl\", \"gu\", \"ha\", \"haw\", \"hi\", \"hr\", \"ht\", \"hu\", \"hy\", \"id\", \"is\", \"it\", \"iw\", \"ja\", \"jw\", \"ka\", \"kk\", \"km\", \"kn\", \"ko\", \"la\", \"lb\", \"ln\", \"lo\", \"lt\", \"lv\", \"mg\", \"mi\", \"mk\", \"ml\", \"mn\", \"mr\", \"ms\", \"mt\", \"my\", \"ne\", \"nl\", \"nn\", \"no\", \"oc\", \"pa\", \"pl\", \"ps\", \"pt\", \"ro\", \"ru\", \"sa\", \"sd\", \"si\", \"sk\", \"sl\", \"sn\", \"so\", \"sq\", \"sr\", \"su\", \"sv\", \"sw\", \"ta\", \"te\", \"tg\", \"th\", \"tk\", \"tl\", \"tr\", \"tt\", \"uk\", \"ur\", \"uz\", \"vi\", \"yi\", \"yo\", \"zh\"]\n",
        "model = \"large-v3\"  # @param [\"large-v3-turbo\", \"distil-large-v3\", \"large-v3\", \"large-v2\", \"medium\", \"base\", \"small\", \"tiny\"]\n",
        "new_line_separator = \" \"  # @param {type:\"string\"} [\"White space ( )\", \"Line feed (\\\\n)\", \"Carriage return + Line feed (\\\\r\\\\n)\", \"Carriage return (\\\\r)\", \" \"]\n",
        "\n",
        "# init\n",
        "new_line_separator = new_line_separators.get(new_line_separator, \" \")\n",
        "is_whisper = converter == \"whisper\"\n",
        "is_faster_whisper = converter == \"faster-whisper\"\n",
        "is_whisper_jax = converter == \"whisper-jax\"\n",
        "is_insanely_fast_whisper = converter == \"insanely-fast-whisper\"\n",
        "mimetypes.init()\n",
        "ydl_opts = {\n",
        "    \"format\": \"m4a/bestaudio/best\",\n",
        "    \"postprocessors\": [\n",
        "        {  # Extract audio using ffmpeg\n",
        "            \"key\": \"FFmpegExtractAudio\",\n",
        "            \"preferredcodec\": \"m4a\",\n",
        "        }\n",
        "    ],\n",
        "    \"playliststart\": int(playlist_start),\n",
        "    \"playlistend\": int(playlist_end),\n",
        "    \"outtmpl\": f\"{str(download_folder)}/%(playlist_index)04d-%(title)s-%(id)s.%(ext)s\",\n",
        "}\n",
        "\n",
        "# Download youtube videos\n",
        "if process_type == \"youtube\":\n",
        "    !~/.local/bin/mise x -- python3 -m pip install --quiet yt_dlp[\"default\"]\n",
        "    import yt_dlp\n",
        "    for url in user_input.split():\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download(url)\n",
        "if process_type == \"google_drive\":\n",
        "    !wget --quiet https://github.com/tanaikech/goodls/releases/download/v2.0.3/goodls_linux_amd64 -O download/goodls && chmod +x download/goodls\n",
        "    for url in user_input.split():\n",
        "        !cd download && ./goodls -u $url\n",
        "if process_type == \"direct_link\":\n",
        "    !cd download && wget $user_input\n",
        "if process_type == \"curl\":\n",
        "    !cd download && $user_input\n",
        "\n",
        "# prepare model\n",
        "if is_faster_whisper:\n",
        "    !~/.local/bin/mise x -- python3 -m pip install --quiet \"faster-whisper @ https://github.com/SYSTRAN/faster-whisper/archive/refs/heads/master.tar.gz\" ctranslate2==4.4.0\n",
        "    from huggingface_hub.utils import _runtime\n",
        "    _runtime._is_google_colab = False\n",
        "    from faster_whisper import WhisperModel, BatchedInferencePipeline\n",
        "    model = BatchedInferencePipeline(model=WhisperModel(model, device=\"cuda\", compute_type=\"float16\"))\n",
        "elif is_whisper_jax:\n",
        "    !~/.local/bin/mise x -- python3 -m pip install --quiet git+https://github.com/sanchit-gandhi/whisper-jax.git\n",
        "    import jax.numpy as jnp\n",
        "    from whisper_jax import FlaxWhisperPipline\n",
        "    model = FlaxWhisperPipline(\n",
        "        f\"openai/whisper-{model}\", dtype=jnp.float16\n",
        "    )\n",
        "elif is_insanely_fast_whisper:\n",
        "    !~/.local/bin/mise x -- python3 -m pip install insanely-fast-whisper\n",
        "    # !pip install flash-attn --no-build-isolation\n",
        "    import torch\n",
        "    from transformers import pipeline\n",
        "    model = pipeline(\"automatic-speech-recognition\",\n",
        "                    f\"openai/whisper-{model}\",\n",
        "                    torch_dtype=torch.float16,\n",
        "                    # model_kwargs={\"use_flash_attention_2\": True},\n",
        "                    device=\"cuda:0\")\n",
        "    model.model = model.model.to_bettertransformer()\n",
        "else:\n",
        "    !~/.local/bin/mise x -- python3 -m pip install --quiet git+https://github.com/openai/whisper.git stable-ts\n",
        "    import whisper\n",
        "    from stable_whisper import modify_model\n",
        "    model = whisper.load_model(model)\n",
        "    # jianfch/stable-ts\n",
        "    modify_model(model)\n",
        "\n",
        "# transcribe\n",
        "for audio_file in sorted(download_folder.iterdir()):\n",
        "    # Filter out non audio or video files\n",
        "    mime = mimetypes.guess_type(audio_file)[0]\n",
        "    if mime is None:\n",
        "        continue\n",
        "    mime_type = mime.split(\"/\")[0]\n",
        "    if mime_type not in (\"audio\", \"video\"):\n",
        "        continue\n",
        "\n",
        "    print(f\"Transcription of {audio_file} will start!\")\n",
        "    text_file = Path(f\"{output_folder}/{audio_file.stem}.txt\")\n",
        "    subtitle_file = Path(f\"{output_folder}/{audio_file.stem}.srt\")\n",
        "\n",
        "    if is_whisper:\n",
        "        result = model.transcribe(str(audio_file), language=language)\n",
        "        # save TXT\n",
        "        with open(str(text_file), \"w\", encoding=\"utf-8\") as txt:\n",
        "            for segment in result[\"segments\"]:\n",
        "                txt.write(segment[\"text\"].strip() + new_line_separator)\n",
        "        # save SRT\n",
        "        # with open(f\"{download_folder}/{audio_file.name}.srt\", \"w\", encoding=\"utf-8\") as srt:\n",
        "        #    whisper.write_srt(result[\"segments\"], file=srt)\n",
        "        result.to_srt_vtt(str(subtitle_file))\n",
        "        ## Write into a text file\n",
        "        # Path(f\"{download_folder}/{file_name.name}.txt\").write_text(result[\"text\"])\n",
        "    else:\n",
        "        if is_faster_whisper:\n",
        "            segments, info = model.transcribe(\n",
        "                str(audio_file), language=language, beam_size=5, batch_size=16\n",
        "            )\n",
        "            print(\n",
        "                \"Detected language '%s' with probability %f\"\n",
        "                % (info.language, info.language_probability)\n",
        "            )\n",
        "            segments_list = []\n",
        "            for segment in segments:\n",
        "                segments_list.append(segment)\n",
        "        if is_whisper_jax:\n",
        "            segments = model(\n",
        "                str(audio_file), language=language, return_timestamps=True\n",
        "            )[\"chunks\"]\n",
        "        if is_insanely_fast_whisper:\n",
        "            segments = model(str(audio_file), chunk_length_s=30, batch_size=24, return_timestamps=True, generate_kwargs={\"language\": language},)[\"chunks\"]\n",
        "        if is_whisper_jax or is_insanely_fast_whisper:\n",
        "          segments_list = [\n",
        "                {\n",
        "                    \"start\": segment[\"timestamp\"][0],\n",
        "                    \"end\": segment[\"timestamp\"][1],\n",
        "                    \"text\": segment[\"text\"],\n",
        "                }\n",
        "                for segment in segments\n",
        "            ]\n",
        "        with open(str(text_file), \"w\", encoding=\"utf-8\") as txt, open(\n",
        "            str(subtitle_file), \"w\", encoding=\"utf-8\"\n",
        "        ) as srt:\n",
        "            write_srt(srt, segments_list)\n",
        "            for segment in segments_list:\n",
        "                txt.write(segment[\"text\"] if isinstance(segment, dict) else segment.text + new_line_separator)\n",
        "    files.download(str(text_file))\n",
        "    files.download(str(subtitle_file))\n",
        "    audio_file.unlink()\n",
        "    print(\"Done!\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}